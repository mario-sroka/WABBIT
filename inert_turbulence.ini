;------------------------------------------------------------
;------------ WABBIT PARAMETER FILE TEMPLATE ----------------
;------------------------------------------------------------
; if you add new parameters, add them here.
; note values have to be declared "value=0;", with equal sign (=) and semicolon (;)


[Domain]
; 2D or 3D problem?
dim=3;
; box size of computational domain. [Lx Ly Lz]
domain_size=0.008 0.008 0.008;
; synchronization (on/off)on [x y z] domain boundaries
; (off (NON-PERIODIC): 0/false/yes | on (PERIODIC): 1/true/no)
periodic_BC=1 1 1;


[Blocks]
; size of each block, must be odd (17, 33, 65 etc),
; if given one value this is meant for all directions, or specify value for each direction
number_block_nodes=17 17 17;
; ghost nodes for each block. It is possible that in current versions, one can only
; set even values
number_ghost_nodes=4;
; maximum number of blocks (heavy data) per proc
number_blocks=30;
; number of equations / components of state vector. Note you have to properly
; adjust this value for the physics module that you use.
; ACM: 3 (2D), 4 (3D)
; Convection: 1 (2D /3D)
; reactive Navier-Stokes: 4 (2D) or 5 (3D) + number of species
number_equations=5;
; threshold value for thresholding wavelet coefficients
eps=1e-3;1e-4;
; treelevel bounds
max_treelevel=2;
min_treelevel=2;
; maximal number of trees in the forest:
max_forest_size=1;
; switch for mesh adaption, 1=on, ...=off
adapt_mesh=0;
; adaptive initial conditon? i.e. create grid to respect error bounds
; default is same value as adapt_mesh
adapt_inicond=0;
; in some situations, it is necessary to create the intial grid, and then refine it for a couple of times.
; for example if one does non-adaptive non-equidistant spatial convergence tests. default is 0.
inicond_refinements=0;
; block distribution for balancing (also used for start distribution)
; [equal | sfc_z | sfc_hilbert]
; equal -> simple uniformly distribution
; sfc_z  -> space filling curve -> z-curve
; sfc_hilbert -> hilbert space filling curve
block_dist=sfc_hilbert;
; coarsening indicator to be used in mesh adaptation [threshold-state-vector,random,threshold-vorticity]
; threshold-state-vector: evaluates wavelet criterion on components of state vector. specify below which ones.
; threshold-vorticity: evaluates wavelet criterion on vorticity
;random
;randomly coarse some blocks. used for testing. note we tag for coarsening
;only once in the first iteration
coarsening_indicator=threshold-state-vector-rns;
; use normalization for eps or not? normalization is done with INFTY norm currently. default
; is no normalization (0). ATTENTION works only for ACM currently (TODO!)
eps_normalized=1;
; which components to use for coarsening_indicator? default is all components.
; active only if coarsening_indicator=threshold-state-vector. select the components, set as
; many as number_equations
; first: give number of components for thresholding
; second: give index in state vector (note: should correspond to given number)
number_of_threshold_state_vector_components=1;
threshold_state_vector_component=1;
; it can be useful to also use the mask function (if penalization is used) for grid adaptation.
; i.e. the grid is always at the finest level on mask interfaces. Careful though: the Penalization
; is implemented on physics-module level, i.e. it is not available for all modules.
threshold_mask=0;
; if this flag is set (1), then blocks on max level have to coarsen, even if their
; details are significant. This is equivalent to ensuring dealiasing. Hence, if set to 1,
; wabbit will evaluate the right hand side of your equation on max_treelevel, but in the mesh
; coarsening it will, regardless of the solution, downsample the result to max_treelevel-1. Your
; expected precision is thus max_treelevel-1, but the computational cost (derivatives and timestep)
; is on max_treelevel.
force_maxlevel_dealiasing=0;
; if desired, we perform more than one time step
; before adapting the grid again. this can further reduce the overhead of adaptivity
; Note: the non-linear terms can create finer scales than resolved on the grid. they
; are usually filtered by the coarsening/refinement round trip. So if you do more than one time step
; on the grid, consider using a filter. default is "1", which is the classical scheme
N_dt_per_grid=1;
; number of state vector components for ghost nodes synchronizing
N_max_components=14;


[Time]
; final time to reach in simulation
time_max=8e-4;
; maximum walltime allowed for simulations (in hours). The run will be stopped if this duration
; is exceeded. This is useful on real clusters, where the walltime of a job is limited, and the
; system kills the job regardless of whether we're done or not. If WABBIT itself ends execution,
; a backup is written and you can resume the simulation right where it stopped. Note you can also
; stop a run using the file "runtime_control" (set runtime_control=save_stop;)
walltime_max=999.9;
; number of time steps performed. if not set, default value is very large
nt=;
; CFL criterium (velocity). Note the time step dt is dictated by the physics modules: some eqns (like
; the heat eqn, which is not implemented) may not even have a CFL restriction.
CFL=1.0;
; CFL critierum for penalization (dt<=CFL_eta*C_eta), if VPM is used. For RungeKuttaGeneric schemes, the constant
; has to be < 1.0 (otherwise the code is unstable). For krylov schemes, it can be greater
; 1, but be careful about the error. This parameter is used by ACM physics module only.
CFL_eta=0.99;
; wabbit can save the heavy data (flow fiels) to HDF5. What is saved depends on the physics modules
; and the section [Saving]. Here you control WHEN you want to save the output: either after a fixed
; number of time steps [fixed_freq], or after a physical time interval [fixed_time]
write_method=fixed_time;
; if write_method=fixed_freq:
; write frequency for output, choose very large number for disabling output on disk
write_freq=2;
; if write_method=fixed_time:
; write time for output
write_time=1e-4;
; fixed time step. if the value is greater 0.0, then the time step is fixed no matter what.
; the setting from the physics modules, which usually decide about dt, are ignored and over-
; written. The default is 0.0, so not used. NOTE: WABBIT still will adjust dt to precisely match
; the time for saving and statistics and the final time, if any of those is not a multiple of dt_fixed.
; In that case, some time steps may be smaller in order to reach those times.
dt_fixed=;
; largest time step, if you want to set one. dt is always smaller than that, if the
; value is greater 0. default is 0.0, so not used. WABBIT overwrites the physics module dt
; by that value, if the timestep is larger than dt_max and dt_max > 0.
dt_max=0.0;
; time-step method. can be either "RungeKuttaGeneric" or "Krylov". In the former case,
; any explicit Runge-Kutta scheme can be set by using the Butcher-Tableau. (RK4 is default) In the latter,
; the number of Krylov subspaces M_krylov can be set.
; [ RungeKuttaGeneric, Krylov ]
time_step_method=RungeKuttaGeneric;
; if time_step_method is krylov, then you can specify the dimension of the krylov subspace
; below. If dynamic subspace dimensions are used, we interpret this number as the maximum
; number of spaces admissible (the method requires a lot of memory in general)
M_krylov=12;
; fixed or dynamic krylov subspace dimension:
; [ fixed, dynamic ]
krylov_subspace_dimension=fixed;
; if dynamic subspace dimensionality is used, provide the residuum threshold here. Note this is
; in general not an exact measure for the error, but rather a good indicator.
krylov_err_threshold=1.0e-3;
; butcher_tableau
; use your butcher_tableau for the Runge Kutta time step function
; e.g. RK4:
; butcher_tableau=(/ 0.0 0.0 0.0 0.0 0.0
; 0.5 0.5 0.0 0.0 0.0
; 0.5 0.0 0.5 0.0 0.0
; 1.0 0.0 0.0 1.0 0.0
; 0.0 0.16666666666666666 0.33333333333333331 0.33333333333333331  0.16666666666666666 /)


[Physics]
; what physics module is used?
; [ACM-new, ConvDiff-new, navier_stokes, reactive_navier_stokes]
physics_type=reactive_navier_stokes;
; decide if you want to start from a given configuration (i.e. Statevector)
; 1:true, 0:false and we start from the initial conditions dictated by the physics
; modue.
read_from_files=1;
; if read_from_files is true, WABBIT will try to start from the given files
; if input_time is non negative (negative=default value), then files are read from field_name+input time.h5
; input_files are ignored in this case
input_time=0;
; file names for reactive navier stokes physics parameter
reactive_parameter_file=combustion.ini;
chemistry_parameter_file=inert_gas.ini;


[Saving]
; WABBIT is in charge of saving, but what is saved is controled by the physics modules.
; here, you need to tell WABBIT how many fields are saved and how they will be labeled.
; The physics modules are then in charge of providing the respective data to WABBIT. I.e.
; if the field is called "mask", WABBIT will ask the physics module to return the array
; "mask" and then save that to disk.
; how many fields are you going to save?
N_fields_saved=6;
; how are the fields labeled?
field_names=rho Ux Uy Uz p vort;

[Statistics]
; save every nsave time steps (leave empty to disable)
nsave_stats=1;
; and every tsave physical time units (leave empty to disable)
tsave_stats=;


[ACM-new]
; ...
[Sponge]
; ...
[ConvectionDiffusion]
; ...
[Navier_Stokes]
; ...
[Boundary_Conditions]
; ...
[Pipe_flow]
; ...

[Initial_Values]
inicond=pressure_blob;
; initial conditions for the different szenarios:
; 1.)mask:
;	  inside penalized volume: velocity u=0,
;                            pressure p=rho_0 Rs T_0,
;   outside: velocity u=u_0 and pressure p=p_0;
; 2.)zeros:
;    sets initial velocitys to 0 regardles of initial_velocity
; 3.)pressure_blob
; 	 pressure blob with diameter inicond_width
; 4.)sod_shock_tube
; 	 sets initial conditions according to [Sod,1978]
; 5.)shear_layer
; 	 set initial conditions (rho_0,u_0,p_0) and the shear layer width from inifile;
; 6.)simple-shock
;    produces standing shock (1D) in x direction, specify inicond_(pressure,velocity,density,width);
;    inicond_width quantifies the shock location in x direction
; 7.)moving-shock
;    produces moving shock (1D) in x direction with initial_velocity(1) specifies shock speed
;    specify inicond_(pressure,velocity,density,inicond_width)
;    inicond_width is the location of the shock
inicond_width=0.01;
initial_pressure=101330.0;  p_0
initial_velocity=50.0 0.0 0; u_0
initial_temperature=200;     T_0
initial_density=1.645;      rho_0

[Discretization]
; order of derivatives [ FD_2nd_central | FD_4th_central_optimized ]
order_discretization=FD_4th_central_optimized;
; order of refinement predictor [ multiresolution_4th | multiresolution_2nd ]
order_predictor=multiresolution_4th;
; filtering of equations. NOTE: the filters are PHYSICS MODULE SPECIFIC! Hence it depends on the module
; which values you can set here.
; cNS: [no_filter | explicit_5pt | explicit_7pt | explicit_9pt | explicit_11pt | bogey_shock | wavelet_filter]
; ACM: [no_filter | wavelet_filter | explicit_7pt]
; ConvDiff: not implemented
; reactive navier stokes: [no_filter | explicit_5pt | explicit_7pt | explicit_9pt | explicit_11pt | wavelet | bogey_shock]
filter_type=explicit_9pt;
; filter frequency (note: set filter to no_filter if you want to disable filtering completely)
; Note our clumsy nomenclature: we mean filtering every "filter_freq" time steps
filter_freq=100;
; usually, a filter would be applied to all blocks, but it is also sometimes useful to apply it just for
; the finest blocks (those that cannot be refined anymore). If maxlevel dealiasing is FALSE and this option is TRUE,
; the result is equivalent to maxlevel_dealiasing TRUE, if the filter is wavelet and it is applied in every time step
filter_only_maxlevel=no;
; bogey shock detector threshold
r_th=1e-5;
; if threshold is reached bogey-filter will be switch on [tanh,abs]
switch=tanh;
; bogey-filter detection method
detector_method=divU
; write out sigma for every n filter iterations (if 0 then sigma is not written out)
save_filter_strength=0;

[Combustion]

[VPM]
; ...
[BRIDGE]
; ...
[Insects]
; ...
[funnel]
; ...
[simple_geometry]
; ...
[Shock_Tube]
; ...


[Debug]
; check if the ghost node synchronization gives the right order, on a random
; grid. this test costs some CPU time but no memory. It is done only once at startup.
test_ghost_nodes_synch=0;
test_treecode=0;
; internal testing routine for the ghost nodes: allocates HUGE amounts of memory
check_redundant_nodes=0;
